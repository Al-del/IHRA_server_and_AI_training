{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:25.434426Z",
     "iopub.status.busy": "2025-07-19T21:59:25.433756Z",
     "iopub.status.idle": "2025-07-19T21:59:25.437224Z",
     "shell.execute_reply": "2025-07-19T21:59:25.436516Z",
     "shell.execute_reply.started": "2025-07-19T21:59:25.434404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:25.446867Z",
     "iopub.status.busy": "2025-07-19T21:59:25.446331Z",
     "iopub.status.idle": "2025-07-19T21:59:55.127043Z",
     "shell.execute_reply": "2025-07-19T21:59:55.126490Z",
     "shell.execute_reply.started": "2025-07-19T21:59:25.446849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>No-Bake Nut Cookies - [\"1 c. firmly packed bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>Jewell Ball'S Chicken - [\"1 small jar chipped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>Creamy Corn - [\"2 (16 oz.) pkg. frozen corn\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>Chicken Funny - [\"1 large whole chicken\", \"2 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>Reeses Cups(Candy)   - [\"1 c. peanut butter\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1  [\"Place chipped beef on bottom of baking dish....   \n",
       "2  [\"In a slow cooker, combine all ingredients. C...   \n",
       "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4  [\"Combine first four ingredients and press in ...   \n",
       "\n",
       "                                                   X  \n",
       "0  No-Bake Nut Cookies - [\"1 c. firmly packed bro...  \n",
       "1  Jewell Ball'S Chicken - [\"1 small jar chipped ...  \n",
       "2  Creamy Corn - [\"2 (16 oz.) pkg. frozen corn\", ...  \n",
       "3  Chicken Funny - [\"1 large whole chicken\", \"2 (...  \n",
       "4  Reeses Cups(Candy)   - [\"1 c. peanut butter\", ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/food-recepies/dataset/full_dataset.csv\")\n",
    "df['X'] = df['title'] + ' - ' + df['ingredients']\n",
    "df = df.drop([\"Unnamed: 0\", \"link\", \"source\", \"NER\", \"title\", \"ingredients\"], axis= 1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:55.128405Z",
     "iopub.status.busy": "2025-07-19T21:59:55.127985Z",
     "iopub.status.idle": "2025-07-19T21:59:55.131097Z",
     "shell.execute_reply": "2025-07-19T21:59:55.130587Z",
     "shell.execute_reply.started": "2025-07-19T21:59:55.128387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:55.131769Z",
     "iopub.status.busy": "2025-07-19T21:59:55.131606Z",
     "iopub.status.idle": "2025-07-19T21:59:59.792858Z",
     "shell.execute_reply": "2025-07-19T21:59:59.792238Z",
     "shell.execute_reply.started": "2025-07-19T21:59:55.131757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a051c81c831a4938adcce5c07b675705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6551e38f6f41499e2c696255c5a060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca6d2440fba4dfe85dce0eeb7ffcee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d443d1af9cf447ce84beab4d8919aa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c462b888014874a6d24dc021abb0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name = \"flax-community/t5-recipe-generation\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.794376Z",
     "iopub.status.busy": "2025-07-19T21:59:59.794157Z",
     "iopub.status.idle": "2025-07-19T21:59:59.797942Z",
     "shell.execute_reply": "2025-07-19T21:59:59.797323Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.794360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_recipe(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=200)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.798727Z",
     "iopub.status.busy": "2025-07-19T21:59:59.798559Z",
     "iopub.status.idle": "2025-07-19T21:59:59.813955Z",
     "shell.execute_reply": "2025-07-19T21:59:59.813451Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.798713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class data_idk(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.X = df[\"X\"]\n",
    "        self.y = df[\"directions\"]\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "full_dataset = data_idk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.814742Z",
     "iopub.status.busy": "2025-07-19T21:59:59.814535Z",
     "iopub.status.idle": "2025-07-19T21:59:59.828634Z",
     "shell.execute_reply": "2025-07-19T21:59:59.828111Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.814726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_len = int(len(full_dataset) * 0.8)\n",
    "valid_len = len(full_dataset) - train_len\n",
    "train_dataset, valid_dataset = random_split(full_dataset, [train_len, valid_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.829362Z",
     "iopub.status.busy": "2025-07-19T21:59:59.829185Z",
     "iopub.status.idle": "2025-07-19T21:59:59.837595Z",
     "shell.execute_reply": "2025-07-19T21:59:59.837087Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.829347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    X_batch, y_batch = zip(*batch)\n",
    "    \n",
    "    X_tokens = tokenizer(\n",
    "        list(X_batch),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    y_tokens = tokenizer(\n",
    "        list(y_batch),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    labels = y_tokens[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": X_tokens[\"input_ids\"],\n",
    "        \"attention_mask\": X_tokens[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.838425Z",
     "iopub.status.busy": "2025-07-19T21:59:59.838228Z",
     "iopub.status.idle": "2025-07-19T21:59:59.848310Z",
     "shell.execute_reply": "2025-07-19T21:59:59.847828Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.838411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, collate_fn= collate_fn, batch_size=16)\n",
    "valid_loader = DataLoader(valid_dataset, collate_fn= collate_fn, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:59:59.849039Z",
     "iopub.status.busy": "2025-07-19T21:59:59.848854Z",
     "iopub.status.idle": "2025-07-19T22:00:00.233673Z",
     "shell.execute_reply": "2025-07-19T22:00:00.233111Z",
     "shell.execute_reply.started": "2025-07-19T21:59:59.849024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 344,064 || all params: 77,305,216 || trainable%: 0.4451\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Original model loading\n",
    "model_name = \"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],  # Modules to apply LoRA to (query and value in attention)\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM  # For sequence-to-sequence models\n",
    ")\n",
    "\n",
    "# Convert model to PEFT model with LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # Should show ~1% of parameters are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:00:00.235403Z",
     "iopub.status.busy": "2025-07-19T22:00:00.235182Z",
     "iopub.status.idle": "2025-07-19T22:00:00.364255Z",
     "shell.execute_reply": "2025-07-19T22:00:00.363613Z",
     "shell.execute_reply.started": "2025-07-19T22:00:00.235386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 1\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:00:00.365525Z",
     "iopub.status.busy": "2025-07-19T22:00:00.365303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Training]: 100%|████████████████████| 5000/5000 [13:22<00:00,  6.23it/s, loss=2.4716]\n",
      "Epoch 1/1 [Validation]:  93%|██████████████████▋ | 1168/1250 [01:22<00:05, 14.66it/s, val_loss=2.0638]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_progress = tqdm(\n",
    "        train_loader, \n",
    "        desc=f'Epoch {epoch+1}/{EPOCHS} [Training]',\n",
    "        bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}'\n",
    "    )\n",
    "    \n",
    "    for batch in train_progress:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        avg_loss = total_train_loss / (train_progress.n + 1)\n",
    "        train_progress.set_postfix({'loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_progress = tqdm(\n",
    "        valid_loader, \n",
    "        desc=f'Epoch {epoch+1}/{EPOCHS} [Validation]',\n",
    "        bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}',\n",
    "        leave=False  \n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_progress:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "            avg_loss = total_val_loss / (val_progress.n + 1)\n",
    "            val_progress.set_postfix({'val_loss': f'{avg_loss:.4f}'})\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(valid_loader)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} Summary:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:29:03.593192Z",
     "iopub.status.busy": "2025-07-19T22:29:03.592567Z",
     "iopub.status.idle": "2025-07-19T22:29:03.596411Z",
     "shell.execute_reply": "2025-07-19T22:29:03.595870Z",
     "shell.execute_reply.started": "2025-07-19T22:29:03.593169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:29:07.514895Z",
     "iopub.status.busy": "2025-07-19T22:29:07.514652Z",
     "iopub.status.idle": "2025-07-19T22:29:07.519328Z",
     "shell.execute_reply": "2025-07-19T22:29:07.518768Z",
     "shell.execute_reply.started": "2025-07-19T22:29:07.514878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_recipe(title_ingredients):\n",
    "    \"\"\"\n",
    "    Generate recipe directions from title and ingredients\n",
    "    Format: \"Title - [ingredient1, ingredient2, ...]\"\n",
    "    \"\"\"\n",
    "    # Preprocess input\n",
    "    text = f\"{title_ingredients['title']} - {title_ingredients['ingredients']}\"\n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=200,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode and return\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:30:23.460326Z",
     "iopub.status.busy": "2025-07-19T22:30:23.459752Z",
     "iopub.status.idle": "2025-07-19T22:30:24.087710Z",
     "shell.execute_reply": "2025-07-19T22:30:24.087206Z",
     "shell.execute_reply.started": "2025-07-19T22:30:23.460304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pour watermelon, Kiwi, Apple and Banana into a blender. Blend until smooth.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_recipe({\"title\" : \"Smoothie\",\n",
    "                \"ingredients\" :\"Watermelon, Kiwi, Apple and Frozen Banana Smoothie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T22:35:29.540426Z",
     "iopub.status.busy": "2025-07-19T22:35:29.539736Z",
     "iopub.status.idle": "2025-07-19T22:35:33.636486Z",
     "shell.execute_reply": "2025-07-19T22:35:33.635963Z",
     "shell.execute_reply.started": "2025-07-19T22:35:29.540404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66e53782543431abba16bab631fc483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/DavidGI23200/recepie_llm_fine_tuned_with_lora/commit/0cae7787b0e047fa7cab3134f8ae049246ae5032', commit_message='Update config with model_type', commit_description='', oid='0cae7787b0e047fa7cab3134f8ae049246ae5032', pr_url=None, repo_url=RepoUrl('https://huggingface.co/DavidGI23200/recepie_llm_fine_tuned_with_lora', endpoint='https://huggingface.co', repo_type='model', repo_id='DavidGI23200/recepie_llm_fine_tuned_with_lora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from transformers import AutoConfig\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"DavidGI23200/recepie_llm_fine_tuned_with_lora\"  # e.g. \"myuser/myawesome-model\"\n",
    "api.create_repo(repo_id=repo_id, exist_ok=True)  # creates repo if not exists\n",
    "\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.push_to_hub(\"DavidGI23200/recepie_llm_fine_tuned_with_lora\", commit_message=\"Update config with model_type\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 7902532,
     "sourceId": 12519416,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
